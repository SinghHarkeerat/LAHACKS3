<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lip Reading & Speech Recognition</title>
    <style>
        :root {
            --primary: #4361ee;
            --secondary: #3f37c9;
            --accent: #4895ef;
            --light: #f8f9fa;
            --dark: #212529;
            --success: #4cc9f0;
            --warning: #f72585;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background-color: var(--light);
            color: var(--dark);
            min-height: 100vh;
            padding: 2rem;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 2rem;
        }

        h1 {
            color: var(--primary);
            margin-bottom: 0.5rem;
        }

        .subtitle {
            color: var(--secondary);
            opacity: 0.8;
        }

        .app-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
        }

        @media (max-width: 768px) {
            .app-grid {
                grid-template-columns: 1fr;
            }
        }

        .video-section,
        .output-section {
            background: white;
            border-radius: 10px;
            padding: 1.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .section-title {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
            color: var(--secondary);
        }

        .section-title svg {
            width: 24px;
            height: 24px;
        }

        .video-container {
            position: relative;
            width: 100%;
            margin-bottom: 1rem;
        }

        video,
        canvas {
            width: 100%;
            border-radius: 8px;
            display: block;
        }

        .lip-mask-container {
            position: relative;
            width: 100%;
            height: 150px;
            background: var(--dark);
            border-radius: 8px;
            overflow: hidden;
            margin-bottom: 1rem;
        }

        #lipMaskCanvas {
            width: 100%;
            height: 100%;
        }

        .controls {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        button {
            padding: 0.5rem 1rem;
            border: none;
            border-radius: 5px;
            background-color: var(--primary);
            color: white;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s;
            flex: 1;
        }

        button:hover {
            background-color: var(--secondary);
            transform: translateY(-2px);
        }

        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .btn-danger {
            background-color: var(--warning);
        }

        .btn-success {
            background-color: var(--success);
        }

        .speech-output {
            height: 300px;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1rem;
            overflow-y: auto;
            background-color: #f8f9fa;
            margin-bottom: 1rem;
        }

        .speech-bubble {
            background-color: white;
            border-radius: 15px;
            padding: 0.75rem 1rem;
            margin-bottom: 0.5rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            position: relative;
            max-width: 80%;
            word-wrap: break-word;
        }

        .speech-bubble.user {
            background-color: var(--primary);
            color: white;
            margin-left: auto;
        }

        .speech-bubble.system {
            background-color: #e9ecef;
            margin-right: auto;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem;
            border-radius: 5px;
            margin-bottom: 1rem;
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background-color: #6c757d;
        }

        .status-dot.active {
            background-color: var(--success);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.2);
            }

            100% {
                transform: scale(1);
            }
        }

        .threshold-control {
            margin-bottom: 1rem;
        }

        label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 500;
        }

        input[type="range"] {
            width: 100%;
        }

        .threshold-value {
            text-align: center;
            font-weight: bold;
            color: var(--primary);
        }
    </style>
</head>

<body>
    <div class="container">
        <header>
            <h1>Lip Reading & Speech Recognition</h1>
            <p class="subtitle">Real-time lip movement detection with speech recognition</p>
        </header>

        <div class="app-grid">
            <div class="video-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                            d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    Video Feed
                </h2>

                <div class="status-indicator">
                    <div class="status-dot" id="cameraStatus"></div>
                    <span id="cameraStatusText">Camera: Loading...</span>
                </div>

                <div class="video-container">
                    <video id="video" playsinline autoplay muted></video>
                    <canvas id="canvas"></canvas>
                </div>

                <div class="lip-mask-container">
                    <canvas id="lipMaskCanvas"></canvas>
                </div>

                <div class="threshold-control">
                    <label for="thresholdSlider">Lip Movement Sensitivity</label>
                    <input type="range" id="thresholdSlider" min="5" max="50" value="20">
                    <div class="threshold-value">Threshold: <span id="thresholdValue">20</span></div>
                </div>

                <div class="controls">
                    <button id="startBtn">Start</button>
                    <button id="stopBtn" disabled>Stop</button>
                </div>
            </div>

            <div class="output-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                            d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                    Speech Output
                </h2>

                <div class="status-indicator">
                    <div class="status-dot" id="speechStatus"></div>
                    <span id="speechStatusText">Speech Recognition: Ready</span>
                </div>

                <div class="speech-output" id="speechOutput">
                    <!-- Speech bubbles will be added here -->
                </div>

                <div class="controls">
                    <button id="clearBtn" class="btn-danger">Clear Output</button>
                    <button id="rephraseBtn" class="btn-success">Rephrase Last</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // DOM Elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const lipMaskCanvas = document.getElementById('lipMaskCanvas');
        const ctx = canvas.getContext('2d');
        const lipCtx = lipMaskCanvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const rephraseBtn = document.getElementById('rephraseBtn');
        const speechOutput = document.getElementById('speechOutput');
        const thresholdSlider = document.getElementById('thresholdSlider');
        const thresholdValue = document.getElementById('thresholdValue');
        const cameraStatus = document.getElementById('cameraStatus');
        const cameraStatusText = document.getElementById('cameraStatusText');
        const speechStatus = document.getElementById('speechStatus');
        const speechStatusText = document.getElementById('speechStatusText');

        // App State
        let stream = null;
        let isRunning = false;
        let isTalking = false;
        let lipDistanceThreshold = 20;
        let speechRecognition = null;
        let lastSpeech = '';
        let model = null;

        // Initialize the app
        async function init() {
            // Set up event listeners
            startBtn.addEventListener('click', startApp);
            stopBtn.addEventListener('click', stopApp);
            clearBtn.addEventListener('click', clearOutput);
            rephraseBtn.addEventListener('click', rephraseLast);
            thresholdSlider.addEventListener('input', updateThreshold);

            // Load face tracking model
            await loadModel();

            // Initialize camera
            initCamera();
        }

        // Load face tracking model
        async function loadModel() {
            try {
                // In a real app, you would load a proper model here
                // For this demo, we'll just simulate it
                console.log("Loading face tracking model...");
                await new Promise(resolve => setTimeout(resolve, 1000));
                console.log("Model loaded");
            } catch (error) {
                console.error("Error loading model:", error);
            }
        }

        // Initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                // Set canvas dimensions to match video
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    lipMaskCanvas.width = 120; // Fixed size for lip mask
                    lipMaskCanvas.height = 80;

                    updateCameraStatus(true);
                });
            } catch (error) {
                console.error("Error accessing camera:", error);
                updateCameraStatus(false, "Camera access denied");
            }
        }

        // Start the application
        function startApp() {
            if (!stream) {
                alert("Please allow camera access first");
                return;
            }

            isRunning = true;
            startBtn.disabled = true;
            stopBtn.disabled = false;

            // Start face tracking
            requestAnimationFrame(trackFace);

            // Start speech recognition
            startSpeechRecognition();

            addSpeechBubble("System", "Application started. Begin speaking...", "system");
        }

        // Stop the application
        function stopApp() {
            isRunning = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;

            // Stop speech recognition
            if (speechRecognition) {
                speechRecognition.stop();
                updateSpeechStatus(false, "Speech Recognition: Stopped");
            }

            addSpeechBubble("System", "Application stopped", "system");
        }

        // Clear the speech output
        function clearOutput() {
            speechOutput.innerHTML = '';
        }

        // Rephrase the last spoken sentence with Quillbot-like functionality
        function rephraseLast() {
            if (!lastSpeech) {
                addSpeechBubble("System", "No speech to rephrase", "system");
                return;
            }

            // Show loading message
            const loadingBubble = document.createElement('div');
            loadingBubble.className = 'speech-bubble system';
            loadingBubble.innerHTML = `<strong>System:</strong> Rephrasing...`;
            speechOutput.appendChild(loadingBubble);
            speechOutput.scrollTop = speechOutput.scrollHeight;

            // Simulate API call delay
            setTimeout(() => {
                // Remove loading message
                speechOutput.removeChild(loadingBubble);

                // Get rephrased versions
                const rephrased = quillbotRephrase(lastSpeech);

                // Display results
                addSpeechBubble("System", `Original: ${lastSpeech}`, "system");
                addSpeechBubble("System", `Rephrased: ${rephrased}`, "system");
            }, 800);
        }

        // Quillbot-style rephrasing with multiple techniques
        function quillbotRephrase(text) {
            // Skip very short texts
            if (text.split(' ').length < 3) {
                return text; // Not enough content to rephrase meaningfully
            }

            // Choose a rephrasing style randomly
            const style = Math.floor(Math.random() * 4);

            switch (style) {
                case 0: return synonymRephrase(text);
                case 1: return restructureSentence(text);
                case 2: return changeVoice(text);
                case 3: return combineTechniques(text);
                default: return text;
            }
        }

        // Replace words with synonyms
        function synonymRephrase(text) {
            const synonymMap = {
                "hello": ["hi", "greetings", "hey there"],
                "good": ["great", "excellent", "superb", "fine"],
                "bad": ["poor", "terrible", "awful", "subpar"],
                "happy": ["joyful", "content", "pleased", "delighted"],
                "sad": ["unhappy", "depressed", "down", "melancholy"],
                "big": ["large", "huge", "enormous", "gigantic"],
                "small": ["little", "tiny", "petite", "miniature"],
                "fast": ["quick", "rapid", "speedy", "swift"],
                "slow": ["leisurely", "sluggish", "unhurried", "gradual"],
                "important": ["significant", "crucial", "vital", "essential"],
                "think": ["believe", "consider", "ponder", "reflect"],
                "make": ["create", "produce", "construct", "fabricate"],
                "use": ["utilize", "employ", "apply", "operate"],
                "help": ["assist", "aid", "support", "guide"],
                "show": ["demonstrate", "display", "exhibit", "present"],
                "tell": ["inform", "notify", "advise", "apprise"],
                "ask": ["inquire", "question", "query", "request"],
                "need": ["require", "want", "demand", "necessitate"],
                "try": ["attempt", "endeavor", "strive", "undertake"],
                "change": ["alter", "modify", "adjust", "transform"],
                "like": ["enjoy", "prefer", "favor", "appreciate"],
                "because": ["since", "as", "due to", "owing to"],
                "if": ["whether", "provided that", "in case", "assuming"],
                "but": ["however", "nevertheless", "yet", "although"],
                "so": ["therefore", "thus", "consequently", "hence"],
                "very": ["extremely", "exceedingly", "immensely", "remarkably"]
            };

            const words = text.split(' ');
            let changed = false;

            for (let i = 0; i < words.length; i++) {
                const word = words[i].toLowerCase().replace(/[.,\/#!$%\^&\*;:{}=\-_`~()]/g, '');
                if (synonymMap[word]) {
                    // Keep original capitalization
                    const isCapitalized = words[i][0] === words[i][0].toUpperCase();
                    const synonyms = synonymMap[word];
                    const replacement = synonyms[Math.floor(Math.random() * synonyms.length)];
                    words[i] = isCapitalized
                        ? replacement.charAt(0).toUpperCase() + replacement.slice(1)
                        : replacement;
                    changed = true;
                }
            }

            return changed ? words.join(' ') : restructureSentence(text);
        }

        // Restructure the sentence without changing meaning
        function restructureSentence(text) {
            // Simple sentence restructuring patterns
            const patterns = [
                // Move prepositional phrases
                {
                    regex: /(.+?)(,?\s+[a-z]+ing\s+.+?)(\s+[a-z]+\s+)([^,.]+)/i,
                    replace: '$1$3$4$2'
                },
                // Change "X is Y" to "Y is what X is"
                {
                    regex: /([A-Z][^ ]+)\s+(is|are|was|were)\s+([^,.]+)/i,
                    replace: '$3 is what $1 $2'
                },
                // Change "I think X" to "X is what I think"
                {
                    regex: /(I\s+[a-z]+\s+)([^,.]+)/i,
                    replace: '$2 is what $1'
                },
                // Change "X can Y" to "Y is possible for X"
                {
                    regex: /([A-Z][^ ]+)\s+(can|could)\s+([^,.]+)/i,
                    replace: '$3 is possible for $1'
                },
                // Change "X should Y" to "Y is what X should do"
                {
                    regex: /([A-Z][^ ]+)\s+(should|must)\s+([^,.]+)/i,
                    replace: '$3 is what $1 $2 do'
                }
            ];

            // Try each pattern until one matches
            for (const pattern of patterns) {
                if (pattern.regex.test(text)) {
                    return text.replace(pattern.regex, pattern.replace);
                }
            }

            // If no patterns matched, try adding a modifier
            const modifiers = [
                "Essentially, ",
                "In other words, ",
                "To put it differently, ",
                "That is to say, ",
                "Put simply, ",
                "In simple terms, "
            ];

            return modifiers[Math.floor(Math.random() * modifiers.length)] + text;
        }

        // Change between active and passive voice
        function changeVoice(text) {
            // Simple active to passive transformations
            const activeToPassive = [
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+ed)\s+([^,.]+)/i,
                    replace: '$3 was $2 by $1'
                },
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+s)\s+([^,.]+)/i,
                    replace: '$3 is $2 by $1'
                },
                {
                    regex: /([A-Z][^ ]+)\s+([a-z]+ing)\s+([^,.]+)/i,
                    replace: '$3 is being $2 by $1'
                }
            ];

            // Simple passive to active transformations
            const passiveToActive = [
                {
                    regex: /([^ ]+)\s+was\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 $2 $1'
                },
                {
                    regex: /([^ ]+)\s+is\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 $2s $1'
                },
                {
                    regex: /([^ ]+)\s+is\s+being\s+([a-z]+ed)\s+by\s+([^,.]+)/i,
                    replace: '$3 is $2ing $1'
                }
            ];

            // Check if sentence is passive
            const isPassive = /(was|is|are|were)\s+[a-z]+ed\s+by/i.test(text);

            if (isPassive) {
                for (const pattern of passiveToActive) {
                    if (pattern.regex.test(text)) {
                        return text.replace(pattern.regex, pattern.replace);
                    }
                }
            } else {
                for (const pattern of activeToPassive) {
                    if (pattern.regex.test(text)) {
                        return text.replace(pattern.regex, pattern.replace);
                    }
                }
            }

            return restructureSentence(text);
        }

        // Combine multiple rephrasing techniques
        function combineTechniques(text) {
            // Apply synonym replacement first
            let rephrased = synonymRephrase(text);

            // If synonym replacement didn't change anything, try restructuring
            if (rephrased === text) {
                rephrased = restructureSentence(text);
            }

            // Randomly decide whether to also change voice
            if (Math.random() > 0.5) {
                const voiceChanged = changeVoice(rephrased);
                if (voiceChanged !== rephrased) {
                    rephrased = voiceChanged;
                }
            }

            return rephrased;
        }

        

        // Update the lip distance threshold
        function updateThreshold() {
            lipDistanceThreshold = parseInt(thresholdSlider.value);
            thresholdValue.textContent = lipDistanceThreshold;
        }

        // Track face and lips
        function trackFace() {
            if (!isRunning) return;

            // Draw video frame to canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Simulate face detection (in a real app, use a proper model)
            const faceRect = {
                x: canvas.width / 2 - 100,
                y: canvas.height / 2 - 100,
                width: 200,
                height: 250
            };

            // Draw face rectangle
            ctx.strokeStyle = '#00FF00';
            ctx.lineWidth = 2;
            ctx.strokeRect(faceRect.x, faceRect.y, faceRect.width, faceRect.height);

            // Simulate lip points (in a real app, detect actual lip landmarks)
            const lipPoints = [];
            const lipCenterX = faceRect.x + faceRect.width / 2;
            const lipCenterY = faceRect.y + faceRect.height * 0.7;
            const lipWidth = 80;
            const lipHeight = 40;

            // Generate lip points in a rough oval shape
            for (let i = 0; i < 12; i++) {
                const angle = (i / 12) * Math.PI * 2;
                const x = lipCenterX + Math.cos(angle) * lipWidth / 2;
                const y = lipCenterY + Math.sin(angle) * lipHeight / 2;
                lipPoints.push({ x, y });

                // Draw lip points
                ctx.fillStyle = '#FF0000';
                ctx.beginPath();
                ctx.arc(x, y, 3, 0, Math.PI * 2);
                ctx.fill();
            }

            // Calculate lip distance (simulated)
            const topLip = lipPoints[3].y;
            const bottomLip = lipPoints[9].y;
            const lipDistance = bottomLip - topLip;

            // Determine if talking based on threshold
            const wasTalking = isTalking;
            isTalking = lipDistance > lipDistanceThreshold;

            // Visual feedback for talking state
            ctx.fillStyle = isTalking ? 'rgba(0, 255, 0, 0.3)' : 'rgba(255, 0, 0, 0.3)';
            ctx.fillRect(faceRect.x, faceRect.y, faceRect.width, faceRect.height);

            // Draw lip distance text
            ctx.fillStyle = '#FFFFFF';
            ctx.font = '20px Arial';
            ctx.fillText(`Lip Distance: ${lipDistance.toFixed(1)}`, 20, 40);
            ctx.fillText(`Threshold: ${lipDistanceThreshold}`, 20, 70);
            ctx.fillText(`Status: ${isTalking ? 'TALKING' : 'NOT TALKING'}`, 20, 100);

            // Extract and display lip region
            extractLipRegion(lipPoints);

            // Continue tracking
            requestAnimationFrame(trackFace);
        }

        // Extract and display the lip region
        function extractLipRegion(lipPoints) {
            // Find bounding box of lips
            let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
            lipPoints.forEach(point => {
                minX = Math.min(minX, point.x);
                minY = Math.min(minY, point.y);
                maxX = Math.max(maxX, point.x);
                maxY = Math.max(maxY, point.y);
            });

            // Add some padding
            const padding = 20;
            minX = Math.max(0, minX - padding);
            minY = Math.max(0, minY - padding);
            maxX = Math.min(canvas.width, maxX + padding);
            maxY = Math.min(canvas.height, maxY + padding);

            // Draw lip region on main canvas (for visualization)
            ctx.strokeStyle = '#FFFF00';
            ctx.lineWidth = 2;
            ctx.strokeRect(minX, minY, maxX - minX, maxY - minY);

            // Draw lip region on lip mask canvas
            lipCtx.clearRect(0, 0, lipMaskCanvas.width, lipMaskCanvas.height);

            // Get image data from the lip region
            const lipImageData = ctx.getImageData(minX, minY, maxX - minX, maxY - minY);

            // Create a temporary canvas to resize the lip region
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = maxX - minX;
            tempCanvas.height = maxY - minY;
            tempCtx.putImageData(lipImageData, 0, 0);

            // Draw resized version to lip mask canvas
            lipCtx.drawImage(tempCanvas, 0, 0, lipMaskCanvas.width, lipMaskCanvas.height);

            // Apply some effects to make it look processed
            const imageData = lipCtx.getImageData(0, 0, lipMaskCanvas.width, lipMaskCanvas.height);
            const data = imageData.data;

            // Enhance contrast (simple algorithm)
            for (let i = 0; i < data.length; i += 4) {
                // Make reds more prominent
                data[i] = Math.min(255, data[i] * 1.2);
                // Reduce greens and blues
                data[i + 1] = data[i + 1] * 0.7;
                data[i + 2] = data[i + 2] * 0.7;
            }

            lipCtx.putImageData(imageData, 0, 0);
        }

        // Start speech recognition
        function startSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window)) {
                updateSpeechStatus(false, "Speech Recognition: Not supported");
                addSpeechBubble("System", "Speech recognition not supported in your browser", "system");
                return;
            }

            speechRecognition = new webkitSpeechRecognition();
            speechRecognition.continuous = true;
            speechRecognition.interimResults = true;

            speechRecognition.onstart = () => {
                updateSpeechStatus(true, "Speech Recognition: Listening...");
            };

            speechRecognition.onerror = (event) => {
                updateSpeechStatus(false, `Speech Recognition: Error (${event.error})`);
            };

            speechRecognition.onend = () => {
                if (isRunning) {
                    // Restart recognition if app is still running
                    speechRecognition.start();
                }
            };

            speechRecognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }

                if (finalTranscript) {
                    lastSpeech = finalTranscript;
                    addSpeechBubble("You", finalTranscript, "user");
                } else if (interimTranscript) {
                    // You could show interim results differently if desired
                }
            };

            speechRecognition.start();
        }

        // Add a speech bubble to the output
        function addSpeechBubble(speaker, text, type) {
            const bubble = document.createElement('div');
            bubble.className = `speech-bubble ${type}`;
            bubble.innerHTML = `<strong>${speaker}:</strong> ${text}`;
            speechOutput.appendChild(bubble);
            speechOutput.scrollTop = speechOutput.scrollHeight;
        }

        // Update camera status indicator
        function updateCameraStatus(active, text = null) {
            cameraStatus.className = `status-dot ${active ? 'active' : ''}`;
            cameraStatusText.textContent = text || (active ? "Camera: Active" : "Camera: Inactive");
        }

        // Update speech recognition status indicator
        function updateSpeechStatus(active, text = null) {
            speechStatus.className = `status-dot ${active ? 'active' : ''}`;
            speechStatusText.textContent = text || (active ? "Speech Recognition: Active" : "Speech Recognition: Inactive");
        }

        // Initialize the app when the page loads
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>

</html>